// src/service/ai_handler.ts

import OpenAI from 'openai';
import type { ChatCompletionMessageParam } from 'openai/resources/chat/completions';
import TurndownService from 'turndown';
import { executeToolCall, getEnabledMcpTools, toOpenAITools } from './mcpTools';


// // åˆå§‹åŒ– HTML è½¬ Markdown çš„æœåŠ¡
// const turndownService = new TurndownService({
//   headingStyle: 'atx',  // ä½¿ç”¨ # æ ‡é¢˜é£æ ¼
//   codeBlockStyle: 'fenced' ,// ä½¿ç”¨ ``` ä»£ç å—é£æ ¼
//   linkStyle: 'inlined' // ä¿æŒé“¾æ¥è·Ÿåœ¨æ–‡å­—åé¢
// });
// // ğŸŒŸ å…³é”®ï¼šè®© Turndown ä¸è¦åˆ æ‰è¡¨æ ¼é‡Œçš„æ¢è¡Œï¼Œä¿ç•™æ›´å¤šç»“æ„
// turndownService.addRule('preserveTable', {
//   filter: ['table', 'tr', 'td', 'th'],
//   replacement: function (content, node) {
//     return (node as any).isBlock ? '\n\n' + content + '\n\n' : content;
//   }
// });

// 1. å®šä¹‰æ¨¡å‹é…ç½®
const CONFIGS: Record<string, any> = {
  // --- DeepSeek R1 (ä½¿ç”¨OpenRouter) ---
  'deepseek-r1': {
    baseURL: 'https://openrouter.ai/api/v1',  // OpenRouteræµåŠ¨åœ°å€
    model: 'deepseek/deepseek-r1',         // OpenRouteræµåŠ¨æ¨¡å‹å
    envKey: 'Openrouter_KEY'       
  },
  
  // --- GPT-4o  ---
  'gpt-4o': {
    baseURL: 'https://openrouter.ai/api/v1',
    model: 'openai/gpt-4o',
    envKey: 'Openrouter_KEY'
  },

  // --- GPT-4o mini  ---
  'gpt-4o-mini': {
    baseURL: 'https://openrouter.ai/api/v1',
    model: 'openai/gpt-4o-mini',
    envKey: 'Openrouter_KEY'
  },

  // --- Claude 3.5  ---
  'claude-3-5': {
    baseURL: 'https://openrouter.ai/api/v1',
    model: 'anthropic/claude-3.5-sonnet',
    envKey: 'Openrouter_KEY'
  }
};

const THINK_TAG_PATTERN = /<think>[\s\S]*?<\/think>/g;


export async function processContent(htmlContent: string, systemPrompt: string,modelId: string = 'deepseek-r1') {
  // 1. å®¹é”™å¤„ç†ï¼šå¦‚æœå‰ç«¯æ²¡ä¼  modelIdï¼Œé»˜è®¤ç”¨ DeepSeek R1
  const config = CONFIGS[modelId] || CONFIGS['gpt-4o'];
  //const template = TEMPLATES[templateId] || TEMPLATES['summary'];

  // 2. è¯»å–å¯¹åº”çš„å¯†ç 
  const currentKey = process.env[config.envKey];
  
  if (!currentKey) {
    // æ²¡å¯†ç æ—¶è¿”å›æ˜ç¡®é”™è¯¯ï¼Œä¸å´©
    return { 
      title: "é…ç½®é”™è¯¯", 
      summary: `æœªæ‰¾åˆ° ${config.envKey}ï¼Œè¯·åœ¨åç«¯ .env æ–‡ä»¶ä¸­é…ç½®`, 
      tags: ["Error"] 
    };
  }

  // ///////////////////////////////ä¼˜åŒ–ï¼ˆzyyï¼‰///////////////////////////////////

  // // ã€æ–°å¢æ­¥éª¤ã€‘æ¸…æ´—æ•°æ®ï¼šHTML -> Markdown
  // // è¿™èƒ½æå¤§å‡å°‘ Token æ¶ˆè€—ï¼Œå¹¶è®©ç»“æ„æ›´æ¸…æ™°
  // console.log(`[AI Service] æ­£åœ¨ä½¿ç”¨${modelId}å°† HTML è½¬æ¢ä¸º Markdown...`);
  // let markdownContent = "";
  // try {
  //   // å¦‚æœä¼ å…¥çš„æ˜¯çº¯æ–‡æœ¬ï¼Œå°±ä¸è½¬äº†ï¼›å¦‚æœæ˜¯ HTMLï¼Œå°±è½¬
  //   if (htmlContent.trim().startsWith('<')) {
  //       markdownContent = turndownService.turndown(htmlContent);
  //   } else {
  //       markdownContent = htmlContent;
  //   }
  // } catch (e) {
  //   console.warn("[AI Service] Markdown è½¬æ¢å¤±è´¥ï¼Œé™çº§ä½¿ç”¨åŸå§‹æ–‡æœ¬", e);
  //   markdownContent = htmlContent;
  // }

  // // æˆªå–é•¿åº¦é™åˆ¶ï¼ˆMarkdown æ›´ç´§å‡‘ï¼Œå¯ä»¥ç•™æ›´å¤šï¼‰
  // const finalInput = markdownContent.substring(0, 50000);

  // ///////////////////////////////ä¼˜åŒ–ç»“æŸ///////////////////////////////////

  // 3. å‡†å¤‡è°ƒç”¨
  const client = new OpenAI({
    baseURL: config.baseURL,
    apiKey: currentKey,
    dangerouslyAllowBrowser: true
  });

  try {

    const completion = await client.chat.completions.create({
      model: config.model,
      messages: [
        { role: "system", content: systemPrompt },
        // { role: "user", content: `è¯·åˆ†æä»¥ä¸‹ç½‘é¡µå†…å®¹ï¼ˆMarkdownæ ¼å¼ï¼‰ï¼š\n\n${finalInput}` }//ä¿®æ­£
        { role: "user", content: `ç½‘é¡µå†…å®¹å¦‚ä¸‹ï¼š\n${htmlContent.substring(0, 15000)}` } 
      ],
      response_format: { type: "json_object" },
      temperature: 0.3,
    });

    const content = completion.choices[0].message.content;
    const cleanContent = content?.replace(/```json|```/g, '').trim();
    
    return JSON.parse(cleanContent || "{}");

  } catch (error: any) {
    console.error("AI Error:", error.message);
    return {
      title: "AI å¤„ç†å¤±è´¥",
      summary: `è°ƒç”¨ ${config.model} å¤±è´¥: ${error.message}`,
      tags: ["Error"]
    };
  }
}





 /**
 * ä¿®æ”¹çº¯å¯¹è¯æ¨¡å¼ (Chat Mode) - æ”¯æŒä¸Šä¸‹æ–‡è®°å¿†
 * @param userMessage ç”¨æˆ·çš„é—®é¢˜
 * @param modelId æ¨¡å‹ID
 * @param context ä¸Šä¸‹æ–‡æ•°æ® (å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–JSONå¯¹è±¡)
 */
export async function processChat(
  userMessage: string,
  modelId: string = 'deepseek-r1',
  context?: unknown,
  toolIds: string[] = [],
) {
  const config = CONFIGS[modelId] || CONFIGS['deepseek-r1'];
  const currentKey = process.env[config.envKey];

  if (!currentKey) {
    return 'âŒ é…ç½®é”™è¯¯: æœªæ‰¾åˆ° API Keyã€‚';
  }

  const client = new OpenAI({
    baseURL: config.baseURL,
    apiKey: currentKey,
    dangerouslyAllowBrowser: true,
    defaultHeaders: {
      'HTTP-Referer': 'https://github.com/SmartClipper',
    },
  });

  const enabledTools = getEnabledMcpTools(Array.isArray(toolIds) ? toolIds : []);
  const hasTools = enabledTools.length > 0;

  const messages: ChatCompletionMessageParam[] = [
    { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„ AI åŠ©æ‰‹ã€‚' },
  ];

  if (hasTools) {
    const toolSummary = enabledTools
      .map((tool) => `- ${tool.name}: ${tool.description}`)
      .join('\n');
    messages.push({
      role: 'system',
      content: `å·²å¯ç”¨ä»¥ä¸‹ MCP å·¥å…·ï¼Œå¯æŒ‰éœ€è°ƒç”¨ï¼š\n${toolSummary}`,
    });
  }

  if (context) {
    const contextStr = typeof context === 'string' ? context : JSON.stringify(context, null, 2);
    messages.push({
      role: 'system',
      content: `ã€å½“å‰ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‘\nç”¨æˆ·æ­£åœ¨æµè§ˆæˆ–è®¨è®ºä»¥ä¸‹å†…å®¹ï¼Œè¯·åŸºäºæ­¤å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š\n\n${contextStr.substring(0, 10000)}`,
    });
  }

  messages.push({ role: 'user', content: userMessage });

  console.log(
    `ğŸ’¬ [Chat] è°ƒç”¨æ¨¡å‹: ${config.model}, ä¸Šä¸‹æ–‡é•¿åº¦: ${context ? JSON.stringify(context).length : 0}, å¯ç”¨å·¥å…·: ${enabledTools.length}`,
  );

  try {
    if (!hasTools) {
      const completion = await client.chat.completions.create({
        model: config.model,
        messages,
        temperature: 0.7,
      });

      const rawContent = completion.choices[0].message.content;
      return cleanAssistantText(asPlainText(rawContent)) || 'ï¼ˆæ— å›å¤ï¼‰';
    }

    const toolPayloads = toOpenAITools(enabledTools);
    const conversation: ChatCompletionMessageParam[] = [...messages];
    let safetyCounter = 0;

    while (safetyCounter < 5) {
      const completion = await client.chat.completions.create({
        model: config.model,
        messages: conversation,
        temperature: 0.7,
        tools: toolPayloads,
        tool_choice: 'auto',
      });

      const assistantMessage = completion.choices[0].message;
      conversation.push({
        role: 'assistant',
        content: assistantMessage.content ?? '',
        tool_calls: assistantMessage.tool_calls,
      } as ChatCompletionMessageParam);

      if (!assistantMessage.tool_calls || assistantMessage.tool_calls.length === 0) {
        return cleanAssistantText(asPlainText(assistantMessage.content)) || 'ï¼ˆæ— å›å¤ï¼‰';
      }

      for (const call of assistantMessage.tool_calls) {
        const toolResult = await executeToolCall(call, enabledTools);
        conversation.push({
          role: 'tool',
          tool_call_id: call.id,
          content: toolResult,
        } as ChatCompletionMessageParam);
      }

      safetyCounter += 1;
    }

    return 'âŒ MCP å·¥å…·è°ƒç”¨å¤±è´¥ï¼šè¶…è¿‡è¿­ä»£ä¸Šé™ã€‚';
  } catch (error: any) {
    console.error('Chat Error:', error);
    return `âŒ å¯¹è¯å¤±è´¥: ${error.message}`;
  }
}

/**
 * AI è§†è§‰è¯†åˆ«åŠŸèƒ½
 * @param imageDataUrl - base64 æ ¼å¼çš„å›¾ç‰‡æ•°æ® URL
 * @param prompt - æç¤ºè¯
 * @param modelId - æ¨¡å‹ IDï¼Œé»˜è®¤ä½¿ç”¨ gpt-4o-mini
 */
function asPlainText(content: unknown): string {
  if (!content) return '';
  if (typeof content === 'string') return content;
  if (Array.isArray(content)) {
    return content
      .map((chunk: unknown) => {
        if (typeof chunk === 'string') return chunk;
        if (
          chunk &&
          typeof chunk === 'object' &&
          'text' in chunk &&
          typeof (chunk as { text?: unknown }).text === 'string'
        ) {
          return (chunk as { text: string }).text;
        }
        return '';
      })
      .join('\n')
      .trim();
  }
  return '';
}

function cleanAssistantText(raw: string): string {
  return raw.replace(THINK_TAG_PATTERN, '').trim();
}

export async function processVision(
  imageDataUrl: string, 
  prompt: string, 
  modelId: string = 'gpt-4o-mini'
) {
  try {
    // è·å–é…ç½®
    const config = CONFIGS[modelId] || CONFIGS['gpt-4o-mini'];
    const currentKey = process.env[config.envKey];

    if (!currentKey) {
      throw new Error(`æœªæ‰¾åˆ° API å¯†é’¥: ${config.envKey}`);
    }

    // åˆ›å»º OpenAI å®¢æˆ·ç«¯
    const client = new OpenAI({
      baseURL: config.baseURL,
      apiKey: currentKey,
    });

    console.log(`[AI Vision] ä½¿ç”¨æ¨¡å‹: ${config.model}`);

    // è°ƒç”¨ Vision API
    const completion = await client.chat.completions.create({
      model: config.model,
      messages: [
        {
          role: 'user',
          content: [
            { type: 'text', text: prompt },
            { 
              type: 'image_url', 
              image_url: { 
                url: imageDataUrl,
                detail: 'high'  // ä½¿ç”¨é«˜æ¸…æ¨¡å¼
              } 
            }
          ]
        }
      ],
      max_tokens: 2000,
      temperature: 0.3,
    });

    const rawContent = completion.choices[0].message.content || "ï¼ˆAI æ— å›å¤ï¼‰";
    
    // æ¸…æ´—æ€è€ƒè¿‡ç¨‹æ ‡ç­¾
    const cleanContent = rawContent.replace(/<think>[\s\S]*?<\/think>/g, '').trim();
    
    console.log('[AI Vision] è¯†åˆ«å®Œæˆ');
    return cleanContent;

  } catch (error: any) {
    console.error('[AI Vision] é”™è¯¯:', error);
    throw new Error(`AI è¯†å›¾å¤±è´¥: ${error.message}`);
  }
}