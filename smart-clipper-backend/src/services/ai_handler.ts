// src/service/ai_handler.ts

import OpenAI from 'openai';

// 1. å®šä¹‰æ¨¡å‹é…ç½®
const CONFIGS: Record<string, any> = {
  // --- DeepSeek R1 (ä½¿ç”¨OpenRouter) ---
  'deepseek-r1': {
    baseURL: 'https://openrouter.ai/api/v1',  // OpenRouteræµåŠ¨åœ°å€
    model: 'deepseek/deepseek-r1',         // OpenRouteræµåŠ¨æ¨¡å‹å
    envKey: 'Openrouter_KEY'       
  },
  
  // --- GPT-4o  ---
  'gpt-4o': {
    baseURL: 'https://openrouter.ai/api/v1',
    model: 'openai/gpt-4o',
    envKey: 'Openrouter_KEY'
  },

  // --- GPT-4o mini  ---
  'gpt-4o-mini': {
    baseURL: 'https://openrouter.ai/api/v1',
    model: 'openai/gpt-4o-mini',
    envKey: 'Openrouter_KEY'
  },

  // --- Claude 3.5  ---
  'claude-3-5': {
    baseURL: 'https://openrouter.ai/api/v1',
    model: 'anthropic/claude-3.5-sonnet',
    envKey: 'Openrouter_KEY'
  }
};

// // 2. å®šä¹‰å¤„ç†æ¨¡ç‰ˆ
// const TEMPLATES: Record<string, any> = {
//   'summary': {
//     system: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ‘˜è¦åŠ©æ‰‹ã€‚è¯·æŠŠç”¨æˆ·çš„å†…å®¹æ€»ç»“ä¸º JSON æ ¼å¼ï¼ŒåŒ…å« title(æ ‡é¢˜), summary(æ‘˜è¦), tags(æ ‡ç­¾æ•°ç»„)ã€‚ä¸è¦è¾“å‡º markdown æ ‡è®°ã€‚'
//   },
//   'table': {
//     system: 'ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æå¸ˆã€‚è¯·æå–å†…å®¹ä¸­çš„å…³é”®æ•°æ®ï¼Œæ•´ç†ä¸º columns(åˆ—åæ•°ç»„) å’Œ data(è¡Œæ•°æ®æ•°ç»„) çš„ JSON æ ¼å¼ã€‚'
//   },
//   'list': {
//     system: 'ä½ æ˜¯ä¸€ä¸ªå¾…åŠäº‹é¡¹æ•´ç†å‘˜ã€‚è¯·æå–å†…å®¹ä¸º checkItems æ•°ç»„ï¼Œæ¯é¡¹åŒ…å« text(å†…å®¹) å’Œ checked(false)ã€‚è¿”å› JSONã€‚'
//   }
// };

export async function processContent(htmlContent: string, templateId: string, systemPrompt: string,modelId: string = 'deepseek-r1') {
  // 1. å®¹é”™å¤„ç†ï¼šå¦‚æœå‰ç«¯æ²¡ä¼  modelIdï¼Œé»˜è®¤ç”¨ DeepSeek R1
  const config = CONFIGS[modelId] || CONFIGS['deepseek-r1'];
  //const template = TEMPLATES[templateId] || TEMPLATES['summary'];

  // 2. è¯»å–å¯¹åº”çš„å¯†ç 
  const currentKey = process.env[config.envKey];
  
  if (!currentKey) {
    // æ²¡å¯†ç æ—¶è¿”å›æ˜ç¡®é”™è¯¯ï¼Œä¸å´©
    return { 
      title: "é…ç½®é”™è¯¯", 
      summary: `æœªæ‰¾åˆ° ${config.envKey}ï¼Œè¯·åœ¨åç«¯ .env æ–‡ä»¶ä¸­é…ç½®`, 
      tags: ["Error"] 
    };
  }

  // 3. å‡†å¤‡è°ƒç”¨
  const client = new OpenAI({
    baseURL: config.baseURL,
    apiKey: currentKey,
    dangerouslyAllowBrowser: true
  });

  try {

    const completion = await client.chat.completions.create({
      model: config.model,
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: `ç½‘é¡µå†…å®¹å¦‚ä¸‹ï¼š\n${htmlContent.substring(0, 15000)}` } 
      ],
      response_format: { type: "json_object" },
      temperature: 0.3,
    });

    const content = completion.choices[0].message.content;
    const cleanContent = content?.replace(/```json|```/g, '').trim();
    
    return JSON.parse(cleanContent || "{}");

  } catch (error: any) {
    console.error("AI Error:", error.message);
    return {
      title: "AI å¤„ç†å¤±è´¥",
      summary: `è°ƒç”¨ ${config.model} å¤±è´¥: ${error.message}`,
      tags: ["Error"]
    };
  }
}


 /**
 * ä¿®æ”¹çº¯å¯¹è¯æ¨¡å¼ (Chat Mode) - æ”¯æŒä¸Šä¸‹æ–‡è®°å¿†
 * @param userMessage ç”¨æˆ·çš„é—®é¢˜
 * @param modelId æ¨¡å‹ID
 * @param context ä¸Šä¸‹æ–‡æ•°æ® (å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–JSONå¯¹è±¡)
 */
export async function processChat(userMessage: string, modelId: string = 'deepseek-r1', context?: any) {
  const config = CONFIGS[modelId] || CONFIGS['deepseek-r1'];
  const currentKey = process.env[config.envKey];

  if (!currentKey) {
    return "âŒ é…ç½®é”™è¯¯: æœªæ‰¾åˆ° API Keyã€‚";
  }

  const client = new OpenAI({
    baseURL: config.baseURL,
    apiKey: currentKey,
    dangerouslyAllowBrowser: true,
    defaultHeaders: {
      "HTTP-Referer": "https://github.com/SmartClipper", 
    }
  });

  // æ„å»ºæ¶ˆæ¯åˆ—è¡¨
  const messages: any[] = [
    { role: "system", content: "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„ AI åŠ©æ‰‹ã€‚" }
  ];

  // å¦‚æœæœ‰ä¸Šä¸‹æ–‡ï¼ŒæŠŠå®ƒå¡ç»™ AI
  if (context) {
    const contextStr = typeof context === 'string' ? context : JSON.stringify(context, null, 2);
    messages.push({
      role: "system", 
      content: `ã€å½“å‰ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‘\nç”¨æˆ·æ­£åœ¨æµè§ˆæˆ–è®¨è®ºä»¥ä¸‹å†…å®¹ï¼Œè¯·åŸºäºæ­¤å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š\n\n${contextStr.substring(0, 10000)}` // é™åˆ¶é•¿åº¦é˜²æŠ¥é”™
    });
  }

  // æœ€åæ”¾å…¥ç”¨æˆ·çš„é—®é¢˜
  messages.push({ role: "user", content: userMessage });

  console.log(`ğŸ’¬ [Chat] è°ƒç”¨æ¨¡å‹: ${config.model}, ä¸Šä¸‹æ–‡é•¿åº¦: ${context ? JSON.stringify(context).length : 0}`);

  try {
    const completion = await client.chat.completions.create({
      model: config.model,
      messages: messages,
      temperature: 0.7,
    });

    const rawContent = completion.choices[0].message.content || "ï¼ˆæ— å›å¤ï¼‰";
    // æ¸…æ´— R1 æ€è€ƒè¿‡ç¨‹
    const cleanContent = rawContent.replace(/<think>[\s\S]*?<\/think>/g, '').trim();
    
    return cleanContent;

  } catch (error: any) {
    console.error("Chat Error:", error);
    return `âŒ å¯¹è¯å¤±è´¥: ${error.message}`;
  }
}