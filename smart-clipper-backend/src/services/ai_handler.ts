/* // src/service/ai_handler.ts

import OpenAI from 'openai';

// 1. å®šä¹‰æ¨¡å‹é…ç½®
const CONFIGS: Record<string, any> = {
  // --- DeepSeek R1 (æ‰€ä»¥aiæ¨¡å‹å…¨éƒ¨ä½¿ç”¨OpenRouterçš„èšåˆAPIè°ƒç”¨)ï¼ˆèƒ¡ï¼‰
  'deepseek-r1': {
    baseURL: 'https://openrouter.ai/api/v1'   //æ›´æ”¹ä¸ºOpenRouteråœ°å€  ï¼ˆèƒ¡ï¼‰
    model: 'deepseek/deepseek-r1'             //æ›´æ”¹ä¸ºOpenRouteæ¨¡å‹å ï¼ˆèƒ¡ï¼‰
    envKey: 'Openrouter_KEY'    
  },
  
  // --- GPT-4o  ---
  'gpt-4o': {
    baseURL: 'https://openrouter.ai/api/v1'
    model: 'openai/gpt-4'
    envKey: 'Openrouter_KEY'
  },

  // --- GPT-4o mini  ---
  'gpt-4o-mini': {
    baseURL: 'https://openrouter.ai/api/v1'
    model: 'openai/gpt-4o-mini'
    envKey: 'Openrouter_KEY'
  },

  // --- Claude 3.5  ---
  'claude-3-5': {
    baseURL: 'https://openrouter.ai/api/v1'
    model: 'anthropic/claude-3.5-sonnet'
    envKey: 'Openrouter_KEY'
  }
};

// // 2. å®šä¹‰å¤„ç†æ¨¡ç‰ˆ
// const TEMPLATES: Record<string, any> = {
//   'summary': {
//     system: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ‘˜è¦åŠ©æ‰‹ã€‚è¯·æŠŠç”¨æˆ·çš„å†…å®¹æ€»ç»“ä¸º JSON æ ¼å¼ï¼ŒåŒ…å« title(æ ‡é¢˜), summary(æ‘˜è¦), tags(æ ‡ç­¾æ•°ç»„)ã€‚ä¸è¦è¾“å‡º markdown æ ‡è®°ã€‚'
//   },
//   'table': {
//     system: 'ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æå¸ˆã€‚è¯·æå–å†…å®¹ä¸­çš„å…³é”®æ•°æ®ï¼Œæ•´ç†ä¸º columns(åˆ—åæ•°ç»„) å’Œ data(è¡Œæ•°æ®æ•°ç»„) çš„ JSON æ ¼å¼ã€‚'
//   },
//   'list': {
//     system: 'ä½ æ˜¯ä¸€ä¸ªå¾…åŠäº‹é¡¹æ•´ç†å‘˜ã€‚è¯·æå–å†…å®¹ä¸º checkItems æ•°ç»„ï¼Œæ¯é¡¹åŒ…å« text(å†…å®¹) å’Œ checked(false)ã€‚è¿”å› JSONã€‚'
//   }
// };

export async function processContent(htmlContent: string, templateId: string, systemPrompt: string,modelId: string = 'deepseek-r1') {
  // 1. å®¹é”™å¤„ç†ï¼šå¦‚æœå‰ç«¯æ²¡ä¼  modelIdï¼Œé»˜è®¤ç”¨ DeepSeek R1
  const config = CONFIGS[modelId] || CONFIGS['deepseek-r1'];
  // const template = TEMPLATES[templateId] || TEMPLATES['summary'];

  // 2. è¯»å–å¯¹åº”çš„å¯†ç 
  const currentKey = process.env[config.envKey];
  
  if (!currentKey) {
    // æ²¡å¯†ç æ—¶è¿”å›æ˜ç¡®é”™è¯¯ï¼Œä¸å´©
    return { 
      title: "é…ç½®é”™è¯¯", 
      summary: `æœªæ‰¾åˆ° ${config.envKey}ï¼Œè¯·åœ¨åç«¯ .env æ–‡ä»¶ä¸­é…ç½®`, 
      tags: ["Error"] 
    };
  }

  // 3. å‡†å¤‡è°ƒç”¨
  const client = new OpenAI({
    baseURL: config.baseURL,
    apiKey: currentKey,
    dangerouslyAllowBrowser: true
  });

  try {
    const completion = await client.chat.completions.create({
      model: config.model,
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: `ç½‘é¡µå†…å®¹å¦‚ä¸‹ï¼š\n${htmlContent.substring(0, 15000)}` } 
      ],
      response_format: { type: "json_object" },
      temperature: 0.3,
    });

    const content = completion.choices[0].message.content;
    const cleanContent = content?.replace(/```json|```/g, '').trim();
    
    return JSON.parse(cleanContent || "{}");

  } catch (error: any) {
    console.error("AI Error:", error.message);
    return {
      title: "AI å¤„ç†å¤±è´¥",
      summary: `è°ƒç”¨ ${config.model} å¤±è´¥: ${error.message}`,
      tags: ["Error"]
    };
  }
}

/**
 * aiå¯¹è¯æ¨¡å‹
 * ä¸å¼ºåˆ¶ JSONï¼Œæ”¯æŒè‡ªç”±æ–‡æœ¬å›å¤
 */
/*
export async function processChat(userMessage: string, modelId: string = 'deepseek-r1') {
  const config = CONFIGS[modelId] || CONFIGS['deepseek-r1'];
  const currentKey = process.env[config.envKey];

  if (!currentKey) {
    return "âŒ é…ç½®é”™è¯¯: æœªæ‰¾åˆ° API Keyï¼Œè¯·æ£€æŸ¥æœåŠ¡å™¨ .env æ–‡ä»¶ã€‚";
  }

  const client = new OpenAI({
    baseURL: config.baseURL,
    apiKey: currentKey,
    dangerouslyAllowBrowser: true
  });

  console.log(`ğŸ’¬ [Chat] æ”¶åˆ°æ¶ˆæ¯: ${userMessage.substring(0, 20)}... ä½¿ç”¨æ¨¡å‹: ${config.model}`);

  try {
    const completion = await client.chat.completions.create({
      model: config.model,
      messages: [
        // è¿™é‡Œçš„ Prompt è®¾å®šä¸ºé€šç”¨åŠ©æ‰‹ï¼Œè€Œä¸æ˜¯ JSON æå–æœºå™¨
        { role: "system", content: "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„ AI åŠ©æ‰‹ã€‚è¯·ç”¨ç®€æ´ã€ä¸“ä¸šçš„è¯­è¨€å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚" },
        { role: "user", content: userMessage }
      ],
      // âŒ æ³¨æ„ï¼šè¿™é‡Œåƒä¸‡ä¸èƒ½åŠ  response_format: { type: "json_object" }
      temperature: 0.7, // ç¨å¾®é«˜ä¸€ç‚¹ï¼Œè®©å¯¹è¯æ›´è‡ªç„¶
    });

    const rawContent = completion.choices[0].message.content || "ï¼ˆæ— å›å¤ï¼‰";
    
    // ä¾ç„¶æ¸…æ´—æ‰ R1 çš„æ€è€ƒè¿‡ç¨‹ï¼Œåªä¿ç•™ç»“è®º
    const cleanContent = rawContent.replace(/<think>[\s\S]*?<\/think>/g, '').trim();
    
    return cleanContent;

  } catch (error: any) {
    console.error("Chat Error:", error);
    return `âŒ å¯¹è¯è¯·æ±‚å¤±è´¥: ${error.message}`;
  }
}
 */

 // src/service/ai_handler.ts

import OpenAI from 'openai';

// 1. å®šä¹‰æ¨¡å‹é…ç½®
const CONFIGS: Record<string, any> = {
  // --- DeepSeek R1 (ä½¿ç”¨OpenRouter) ---
  'deepseek-r1': {
    baseURL: 'https://openrouter.ai/api/v1',  // OpenRouteræµåŠ¨åœ°å€
    model: 'deepseek/deepseek-r1',         // OpenRouteræµåŠ¨æ¨¡å‹å
    envKey: 'Openrouter_KEY'       
  },
  
  // --- GPT-4o  ---
  'gpt-4o': {
    baseURL: 'https://openrouter.ai/api/v1',
    model: 'openai/gpt-4o',
    envKey: 'Openrouter_KEY'
  },

  // --- GPT-4o mini  ---
  'gpt-4o-mini': {
    baseURL: 'https://openrouter.ai/api/v1',
    model: 'openai/gpt-4o-mini',
    envKey: 'Openrouter_KEY'
  },

  // --- Claude 3.5  ---
  'claude-3-5': {
    baseURL: 'https://openrouter.ai/api/v1',
    model: 'anthropic/claude-3.5-sonnet',
    envKey: 'Openrouter_KEY'
  }
};

// // 2. å®šä¹‰å¤„ç†æ¨¡ç‰ˆ
// const TEMPLATES: Record<string, any> = {
//   'summary': {
//     system: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ‘˜è¦åŠ©æ‰‹ã€‚è¯·æŠŠç”¨æˆ·çš„å†…å®¹æ€»ç»“ä¸º JSON æ ¼å¼ï¼ŒåŒ…å« title(æ ‡é¢˜), summary(æ‘˜è¦), tags(æ ‡ç­¾æ•°ç»„)ã€‚ä¸è¦è¾“å‡º markdown æ ‡è®°ã€‚'
//   },
//   'table': {
//     system: 'ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æå¸ˆã€‚è¯·æå–å†…å®¹ä¸­çš„å…³é”®æ•°æ®ï¼Œæ•´ç†ä¸º columns(åˆ—åæ•°ç»„) å’Œ data(è¡Œæ•°æ®æ•°ç»„) çš„ JSON æ ¼å¼ã€‚'
//   },
//   'list': {
//     system: 'ä½ æ˜¯ä¸€ä¸ªå¾…åŠäº‹é¡¹æ•´ç†å‘˜ã€‚è¯·æå–å†…å®¹ä¸º checkItems æ•°ç»„ï¼Œæ¯é¡¹åŒ…å« text(å†…å®¹) å’Œ checked(false)ã€‚è¿”å› JSONã€‚'
//   }
// };

export async function processContent(htmlContent: string, systemPrompt: string,templateId: string,modelId: string = 'deepseek-r1') {
  // 1. å®¹é”™å¤„ç†ï¼šå¦‚æœå‰ç«¯æ²¡ä¼  modelIdï¼Œé»˜è®¤ç”¨ DeepSeek R1
  const config = CONFIGS[modelId] || CONFIGS['deepseek-r1'];
  // const template = TEMPLATES[templateId] || TEMPLATES['summary'];

  // 2. è¯»å–å¯¹åº”çš„å¯†ç 
  const currentKey = process.env[config.envKey];

  if (!currentKey) {
    // æ²¡å¯†ç æ—¶è¿”å›æ˜ç¡®é”™è¯¯ï¼Œä¸å´©
    return { 
      title: "é…ç½®é”™è¯¯", 
      summary: `æœªæ‰¾åˆ° ${config.envKey}ï¼Œè¯·åœ¨åç«¯ .env æ–‡ä»¶ä¸­é…ç½®`, 
      tags: ["Error"] 
    };
  }

  // 3. å‡†å¤‡è°ƒç”¨
  const client = new OpenAI({
    baseURL: config.baseURL,
    apiKey: currentKey,
    dangerouslyAllowBrowser: true
  });

  try {
    const completion = await client.chat.completions.create({
      model: config.model,
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: `ç½‘é¡µå†…å®¹å¦‚ä¸‹ï¼š\n${htmlContent.substring(0, 15000)}` } 
      ],
      response_format: { type: "json_object" },
      temperature: 0.3,
    });

    const content = completion.choices[0].message.content;
    const cleanContent = content?.replace(/```json|```/g, '').trim()|| "";
    
    return JSON.parse(cleanContent || "{}");

  } catch (error: any) {
    console.error("AI Error:", error.message);
    return {
      title: "AI å¤„ç†å¤±è´¥",
      summary: `è°ƒç”¨ ${config.model} å¤±è´¥: ${error.message}`,
      tags: ["Error"]
    };
  }
} 


/**
 * çº¯å¯¹è¯æ¨¡å¼    ï¼ˆèƒ¡ï¼‰
 * ä¸å¼ºåˆ¶ JSONï¼Œæ”¯æŒè‡ªç”±æ–‡æœ¬å›å¤
 */

export async function processChat(userMessage: string, modelId: string = 'deepseek-r1') {
  const config = CONFIGS[modelId] || CONFIGS['deepseek-r1'];
  const currentKey = process.env[config.envKey];

  if (!currentKey) {
    return "âŒ é…ç½®é”™è¯¯: æœªæ‰¾åˆ° API Keyï¼Œè¯·æ£€æŸ¥æœåŠ¡å™¨ .env æ–‡ä»¶ã€‚";
  }

  const client = new OpenAI({
    baseURL: config.baseURL,
    apiKey: currentKey,
    dangerouslyAllowBrowser: true
  });

  console.log(`ğŸ’¬ [Chat] æ”¶åˆ°æ¶ˆæ¯: ${userMessage.substring(0, 20)}... ä½¿ç”¨æ¨¡å‹: ${config.model}`);

  try {
    const completion = await client.chat.completions.create({
      model: config.model,
      messages: [
        // è¿™é‡Œçš„ Prompt è®¾å®šä¸ºé€šç”¨åŠ©æ‰‹ï¼Œè€Œä¸æ˜¯ JSON æå–æœºå™¨
        { role: "system", content: "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„ AI åŠ©æ‰‹ã€‚è¯·ç”¨ç®€æ´ã€ä¸“ä¸šçš„è¯­è¨€å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚" },
        { role: "user", content: userMessage }
      ],
      // âŒ æ³¨æ„ï¼šè¿™é‡Œåƒä¸‡ä¸èƒ½åŠ  response_format: { type: "json_object" }
      temperature: 0.7, // ç¨å¾®é«˜ä¸€ç‚¹ï¼Œè®©å¯¹è¯æ›´è‡ªç„¶
    });

    const rawContent = completion.choices[0].message.content || "ï¼ˆæ— å›å¤ï¼‰";
    
    // ä¾ç„¶æ¸…æ´—æ‰ R1 çš„æ€è€ƒè¿‡ç¨‹ï¼Œåªä¿ç•™ç»“è®º
    const cleanContent = rawContent.replace(/<think>[\s\S]*?<\/think>/g, '').trim();
    
    return cleanContent;

  } catch (error: any) {
    console.error("Chat Error:", error);
    return `âŒ å¯¹è¯è¯·æ±‚å¤±è´¥: ${error.message}`;
  }
}
 